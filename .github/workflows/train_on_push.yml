# This assumes train_model.py pulls data from S3 and trains locally within the GitHub runner
# (cheap and Lambda-free).

name: Train Model on Push

on:
  push:
    branches: [main]

jobs:
  train:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PYTHONPATH:$(pwd)" >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Train and Upload Model
        run: |
          python -c "
          from src.prepare_data import load_and_prepare_data
          from src.train_model import train_delivery_model, upload_to_s3

          df, X_cols, y_col, encoder = load_and_prepare_data('amazon_delivery.csv')
          model = train_delivery_model(df[X_cols], df[y_col])
          upload_to_s3('models/delivery_time_model.pkl', encoder)
          "
